# GPTJ-LoRA-finetuning
Repo to fine tune GPTJ using PEFT and training only LoRA adapters
